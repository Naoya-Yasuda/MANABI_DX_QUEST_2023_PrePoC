{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# カレントディレクトリを.pyと合わせるために以下を実行\n",
    "from pathlib import Path\n",
    "if Path.cwd().name == \"notebook\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# 設定\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# NumPy配列の表示オプションを設定\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "# 配列の表示形式を科学表記ではなく通常の浮動小数点数に設定\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac Matplotlibのデフォルトフォントをヒラギノ角ゴシックに設定\n",
    "plt.rcParams['font.family'] = 'Hiragino Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows MatplotlibのデフォルトフォントをMeiryoに設定\n",
    "# plt.rcParams['font.family'] = 'Meiryo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルを読み込む\n",
    "file_path = 'data/input/user_info_cleansing.csv'  # ファイルパスを適切に設定してください\n",
    "df1 = dd.read_csv(file_path).drop(['Unnamed: 0'], axis=1).compute()\n",
    "file_path = 'data/input/gacha_history.csv'  # ファイルパスを適切に設定してください\n",
    "df2 = dd.read_csv(file_path).compute()\n",
    "file_path = 'data/input/point_history_cleansing.csv'  # ファイルパスを適切に設定してください\n",
    "# column_types = {\n",
    "#     'id' : np.float16,\n",
    "#     'user_id' : int,\n",
    "#     'series_id' : np.float16,\n",
    "#     'shop_id' : np.float16,\n",
    "#     'shop_name' : str,\n",
    "#     'card_id' : str,\n",
    "#     'リサイクル分類ID' : np.float16,\n",
    "#     'amount' : np.float16,\n",
    "#     'amount_kg' : np.float16,\n",
    "#     'point' : np.float16,\n",
    "#     'total_point' : np.float16,\n",
    "#     'status' : np.float16,\n",
    "#     'total_amount' : np.float16,\n",
    "#     'coin' : np.float16,\n",
    "#     'rank_id' : np.float16,\n",
    "#     'use_date' :   'datetime64[ns]',\n",
    "#     'created_at' : 'datetime64[ns]',\n",
    "#     'updated_at' : 'datetime64[ns]',\n",
    "#     '支店ID' : np.float16,\n",
    "#     'super' : str,\n",
    "#     'prefectures' : str,\n",
    "#     'municipality' : str,\n",
    "#     'shop_name_1' :  str,\n",
    "#     'shop_id_1' :    str,\n",
    "#     'created_at_1' : 'datetime64[ns]',\n",
    "#     'updated_at_1' : 'datetime64[ns]',\n",
    "#     'store_latitude' : np.double,\n",
    "#     'store_longitude' : np.double,\n",
    "# }\n",
    "df3 = dd.read_csv(\n",
    "    file_path,\n",
    "    dtype={\n",
    "        'series_id': 'Int64',\n",
    "        'shop_id': 'Int64',\n",
    "        'shop_id_1': str,\n",
    "        'リサイクル分類ID': 'Int64',\n",
    "        '支店ID': 'Int64',\n",
    "        'rank_id': 'Int64'\n",
    "    }\n",
    ").drop(['Unnamed: 0'], axis=1).compute()\n",
    "\n",
    "file_path = 'data/input/ユーザー基本情報_2023-12-21.csv'\n",
    "df4 = dd.read_csv(file_path, encoding='sjis').compute()\n",
    "\n",
    "データ授受日 = pd.to_datetime('2023-12-06')\n",
    "\n",
    "# '登録日時' 列を datetime オブジェクトに変換（日付の形式は適宜調整してください）\n",
    "df4['登録日時'] = pd.to_datetime(df4['登録日時'])\n",
    "# サービス利用開始からの経過日数\n",
    "df4['サービス利用開始からの経過日数'] = (データ授受日 - df4['登録日時']).dt.days\n",
    "# サービス利用開始からの経過月数\n",
    "df4['サービス利用開始からの経過月数'] = (データ授受日 - df4['登録日時']).dt.days / 30\n",
    "# 経過月数が1未満は1に補正する。月数で割ると月平均が増えてしまうため\n",
    "df4['サービス利用開始からの経過月数'] = df4['サービス利用開始からの経過月数'].apply(lambda x: 1 if x<1 else x)\n",
    "\n",
    "# 不正データnan変換\n",
    "df1 = df1.replace('N', np.nan)\n",
    "df1 = df1.replace('nan', np.nan)\n",
    "df2 = df2.replace('N', np.nan)\n",
    "df2 = df2.replace('nan', np.nan)\n",
    "df3 = df3.replace('N', np.nan)\n",
    "df3 = df3.replace('nan', np.nan)\n",
    "df4 = df4.replace('N', np.nan)\n",
    "df4 = df4.replace('nan', np.nan)\n",
    "\n",
    "#gachaのデータで100以上の獲得データはテストデータとして除外\n",
    "df2 = df2[df2['add_ticket']<=100]\n",
    "# 4月1日以前は削除、mission_type_idの8と9を削除\n",
    "df2 = df2[(df2[\"mission_type_id\"] != 8) & (df2[\"mission_type_id\"] != 9) & (pd.to_datetime(df2[\"mission_achievement_date\"]) >= pd.Timestamp('2023-04-01'))]\n",
    "#pointhistoryの事務局操作データは除外\n",
    "df3 = df3[df3['status'] != 3]\n",
    "# 'total_amount'は全部N\n",
    "df3 = df3.drop(columns=['total_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# birth_dayをdatetimeに変換し、年代を計算\n",
    "df1['birth_day'] = pd.to_datetime(df1['birth_day'], errors='coerce')\n",
    "current_year = pd.Timestamp.now().year\n",
    "df1['age'] = current_year - df1['birth_day'].dt.year\n",
    "# 年齢と性別が欠損している行を削除\n",
    "data_age_gender = df1.dropna(subset=['age', 'gender']).copy()\n",
    "# 年齢を年代に変換\n",
    "bins = [0, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = ['0-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "df1['年代'] = pd.cut(df1['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# # ワンホットエンコーディング\n",
    "# # gender\n",
    "# df1['男'] = df1['gender'].apply(lambda x: 1 if x == '男' else 0)\n",
    "# df1['女'] = df1['gender'].apply(lambda x: 1 if x == '女' else 0)\n",
    "# # 年代\n",
    "# df1['未成年'] = df1['gender'].apply(lambda x: 1 if x == '0-20' else 0)\n",
    "# df1['20代'] = df1['gender'].apply(lambda x: 1 if x == '21-30' else 0)\n",
    "# df1['30代'] = df1['gender'].apply(lambda x: 1 if x == '31-40' else 0)\n",
    "# df1['40代'] = df1['gender'].apply(lambda x: 1 if x == '41-50' else 0)\n",
    "# df1['50代'] = df1['gender'].apply(lambda x: 1 if x == '51-60' else 0)\n",
    "# df1['60代'] = df1['gender'].apply(lambda x: 1 if x == '61-70' else 0)\n",
    "# df1['70代'] = df1['gender'].apply(lambda x: 1 if x == '71-80' else 0)\n",
    "# df1['80代'] = df1['gender'].apply(lambda x: 1 if x == '81-90' else 0)\n",
    "# df1['90代'] = df1['gender'].apply(lambda x: 1 if x == '91-100' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_merge = pd.merge(df1, df4, left_on='id', right_on='利用者ID', how='inner')\n",
    "# 毎月平均リサイクル量\n",
    "df_user_merge['毎月平均リサイクル量'] = df_user_merge['total_recycle_amount'] / df_user_merge['サービス利用開始からの経過月数']\n",
    "# display(df_user_merge[['total_recycle_amount','サービス利用開始からの経過日数','毎月平均リサイクル量']])\n",
    "\n",
    "df_merge_gacha = pd.merge(df2, df_user_merge, left_on='user_uid', right_on='id', how='left')\n",
    "df_merge_gacha = df_merge_gacha.drop(['id_x','id_y'], axis=1)\n",
    "\n",
    "df_merge_point = pd.merge(df3, df_user_merge, left_on='user_id', right_on='id', how='left')\n",
    "df_merge_point = df_merge_point.drop(['id_x','id_y'], axis=1)\n",
    "df_merge_point = df_merge_point[~df_merge_point['サービス利用開始からの経過日数'].isna()]\n",
    "df_merge_point = df_merge_point[~df_merge_point['サービス利用開始からの経過月数'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特徴量候補を列挙\n",
    "ユーザ毎\n",
    "- 毎月平均リサイクル量\n",
    "- 毎月平均リサイクル回数\n",
    "- 毎月平均クラブコインの使用量\n",
    "- 毎月平均ガチャの取得量\n",
    "- 毎月平均ガチャの使用量\n",
    "- 平均rank\n",
    "- 店舗との距離←緯度経度をgeocodeで算出\n",
    "- 店舗のリサイクル許容量\n",
    "- 性別\n",
    "- 年代\n",
    "- カード種類\n",
    "- サービス利用開始からの経過日数\n",
    "\n",
    "### 特徴量算出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 毎月平均リサイクル回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザー別リサイクル回数\n",
    "count = df_merge_point.groupby('user_id').size()\n",
    "count = count.to_frame('リサイクル回数')\n",
    "count = count.reset_index()\n",
    "\n",
    "df_user_merge = pd.merge(df_user_merge, count, left_on='id', right_on='user_id', how='inner')\n",
    "df_user_merge['毎月平均リサイクル回数'] = df_user_merge['リサイクル回数'] / df_user_merge['サービス利用開始からの経過月数']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 毎月平均クラブコインの使用量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0以下が消費データ\n",
    "used_coin = df_merge_point[df_merge_point['coin']<0].groupby('user_id')['coin'].sum()\n",
    "used_coin = used_coin.to_frame('消費クラブコイン合計量').reset_index()\n",
    "\n",
    "df_user_merge = pd.merge(df_user_merge, used_coin, left_on='id',right_on='user_id',how='left')\n",
    "df_user_merge['消費クラブコイン合計量'] = df_user_merge['消費クラブコイン合計量'].fillna(0)\n",
    "df_user_merge['毎月平均クラブコインの使用量'] = df_user_merge['消費クラブコイン合計量'] / df_user_merge['サービス利用開始からの経過月数']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 毎月平均ガチャの取得量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ガチャ取得合計 = df_merge_gacha[df_merge_gacha['add_ticket']>0].groupby('user_uid')['add_ticket'].sum()\n",
    "ガチャ取得合計 = ガチャ取得合計.to_frame('ガチャ取得合計').reset_index()\n",
    "# display(ガチャ取得合計)\n",
    "df_user_merge = pd.merge(df_user_merge, ガチャ取得合計, left_on='id',right_on='user_uid',how='left')\n",
    "df_user_merge['ガチャ取得合計'] = df_user_merge['ガチャ取得合計'].fillna(0)\n",
    "df_user_merge['毎月平均ガチャの取得量'] = df_user_merge['ガチャ取得合計'] / df_user_merge['サービス利用開始からの経過月数']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 毎月平均ガチャの使用量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ガチャ使用量合計 = abs(df_merge_gacha[df_merge_gacha['add_ticket']<0].groupby('user_uid')['add_ticket'].sum())\n",
    "ガチャ使用量合計 = ガチャ使用量合計.to_frame('ガチャ使用量合計').reset_index()\n",
    "# display(ガチャ使用量合計)\n",
    "df_user_merge = pd.merge(df_user_merge, ガチャ使用量合計, left_on='id',right_on='user_uid',how='left')\n",
    "df_user_merge['ガチャ使用量合計'] = df_user_merge['ガチャ使用量合計'].fillna(0)\n",
    "df_user_merge['毎月平均ガチャの使用量'] = df_user_merge['ガチャ使用量合計'] / df_user_merge['サービス利用開始からの経過月数']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 平均rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rank_id'を数値型に変換しようと試みる\n",
    "# 変換できない場合はNaNを返す\n",
    "df_merge_point['rank_id'] = pd.to_numeric(df_merge_point['rank_id'], errors='coerce')\n",
    "\n",
    "平均rank = df_merge_point.groupby('user_id')['rank_id'].mean()\n",
    "平均rank = 平均rank.to_frame('平均rank').reset_index()\n",
    "# display(平均rank)\n",
    "df_user_merge = pd.merge(df_user_merge, 平均rank, left_on='id',right_on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - カード種類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_merge['カード種類'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カードの種類が「nanaco」か「みやぎ生協」かをワンホットエンコーディングする。\n",
    "他は少ないのでエンコーディングしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user_merge['nanaco'] = df_user_merge['カード種類'].apply(lambda x: 1 if x == 'nanaco' else 0)\n",
    "# df_user_merge['みやぎ生協'] = df_user_merge['カード種類'].apply(lambda x: 1 if x == 'みやぎ生協　リサイクルポイントカード' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーIDカラム重複削除\n",
    "df_user_merge = df_user_merge.drop(['user_id_x','user_id_y', 'user_uid_x', 'user_uid_y'], axis=1)\n",
    "df_user_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正規化\n",
    "#### 特徴量候補を列挙\n",
    "ユーザ毎\n",
    "- 毎月平均リサイクル量\n",
    "- 毎月平均リサイクル回数\n",
    "- 毎月平均クラブコインの使用量\n",
    "- 毎月平均ガチャの取得量\n",
    "- 毎月平均ガチャの使用量\n",
    "- 平均rank\n",
    "- 店舗との距離←緯度経度をgeocodeで算出\n",
    "- 店舗のリサイクル許容量\n",
    "- 性別\n",
    "- 年代\n",
    "- カード種類\n",
    "- サービス利用開始からの経過日数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScalerのインスタンスを作成\n",
    "# scaler = MinMaxScaler()\n",
    "# 正規化対象カラム = ['毎月平均リサイクル量','毎月平均リサイクル回数','毎月平均クラブコインの使用量','毎月平均ガチャの取得量','毎月平均ガチャの使用量','平均rank','サービス利用開始からの経過日数']\n",
    "# # プレフィックスを付与した新しいカラム名のリストを生成\n",
    "# 正規化後カラム名 = ['norm_' + col for col in 正規化対象カラム]\n",
    "# # 複数カラムを指定して正規化\n",
    "# df_normalized = pd.DataFrame(scaler.fit_transform(df_user_merge[正規化対象カラム]), columns=正規化後カラム名)\n",
    "# # 正規化されたデータを元のデータフレームに結合\n",
    "# df_user_merge = df_user_merge.join(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカルデータと数値データのカラムを定義\n",
    "categorical_features = [\n",
    "                        'gender',\n",
    "                        '年代',\n",
    "                        'カード種類'\n",
    "                       ]\n",
    "numerical_features = [\n",
    "                      '毎月平均リサイクル量',\n",
    "                      '毎月平均リサイクル回数',\n",
    "                      '毎月平均クラブコインの使用量',\n",
    "                      '毎月平均ガチャの取得量',\n",
    "                      '毎月平均ガチャの使用量',\n",
    "                      '平均rank',\n",
    "                      'サービス利用開始からの経過日数'\n",
    "                     ]\n",
    "\n",
    "# 前処理パイプライン\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "# データを前処理\n",
    "X_processed = preprocessor.fit_transform(df_user_merge)\n",
    "\n",
    "# K-meansモデルの初期化\n",
    "kmeans = KMeans(n_clusters=5, n_init=10, random_state=None) #n_init='auto'となっていましたが、chef手元でエラー出たためn_init=10に変更\n",
    "\n",
    "# モデルの訓練\n",
    "kmeans.fit(X_processed)\n",
    "\n",
    "# クラスタリング結果の取得\n",
    "df_user_merge['ラベル'] = kmeans.labels_\n",
    "\n",
    "display(df_user_merge['ラベル'].value_counts())\n",
    "# 各クラスタの統計を計算\n",
    "# 数値型のデータのみを含む列を選択\n",
    "numeric_cols = df_user_merge.select_dtypes(include=['number'])\n",
    "\n",
    "# クラスタラベルを追加\n",
    "numeric_cols['ラベル'] = kmeans.labels_\n",
    "\n",
    "cluster_stats = numeric_cols.groupby('ラベル').agg(['mean', 'median', 'std'])\n",
    "\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析の方法\n",
    "クラスタ内の統計:\n",
    "\n",
    "各クラスタの要約統計（平均、中央値、標準偏差など）を計算して、クラスタの特性を理解します。\n",
    "特徴量の重要性:\n",
    "\n",
    "クラスタごとの特徴量の平均値や分布を分析し、どの特徴量がクラスタ形成に最も影響を与えているかを評価します。\n",
    "クラスタの比較:\n",
    "\n",
    "異なるクラスタを比較して、それらがどのように異なるか、または共通する特性を持っているかを分析します。\n",
    "ドメイン知識の適用:\n",
    "\n",
    "ドメイン知識を適用して、クラスタの結果をビジネスや研究の文脈で解釈します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化の方法\n",
    "散布図:\n",
    "\n",
    "2次元または3次元の散布図を使用して、クラスタリングされたデータポイントをプロットします。各クラスタは異なる色やマーカーで表示します。\n",
    "高次元データの場合、主成分分析（PCA）やt-SNEなどの次元削減技術を使用して、データを2Dまたは3D空間にマッピングできます。\n",
    "ペアプロット:\n",
    "\n",
    "各特徴量ペアの組み合わせに基づいて散布図のグリッドを作成します。これにより、特徴量間の関係とクラスタの分布を詳細に調べることができます。\n",
    "ヒートマップ:\n",
    "\n",
    "クラスタの中心点をヒートマップで表示し、各クラスタの特徴を比較します。\n",
    "シルエットプロット:\n",
    "\n",
    "クラスタリングの品質を評価するためにシルエットスコアを可視化します。このスコアは、クラスタ内の密度とクラスタ間の分離を測定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PCA でのデータのプロット\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_processed)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1],alpha=0.3,s=20, c=kmeans.labels_)\n",
    "plt.title(\"PCA-based Scatter Plot of Clusters\")\n",
    "plt.xlim(0,20)\n",
    "# plt.ylim(-10,10)\n",
    "plt.show()\n",
    "\n",
    "# シルエットスコアの計算とプロット\n",
    "silhouette_vals = silhouette_samples(X_processed, kmeans.labels_)\n",
    "# シルエットプロットの実装コード...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeansの結果可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeansのクラスタリング結果について、任意の説明変数2つで散布図を描写するなどして、直感的な理解を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のペアを選択\n",
    "x = '毎月平均リサイクル量'\n",
    "y = '平均rank'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=30, alpha=0.5)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xlim(0, 500)\n",
    "#plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のペアを選択\n",
    "x = '毎月平均リサイクル量'\n",
    "y = 'サービス利用開始からの経過日数'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=30, alpha=0.5)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xlim(0, 500)\n",
    "#plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のペアを選択\n",
    "x = '毎月平均クラブコインの使用量'\n",
    "y = 'サービス利用開始からの経過日数'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=30, alpha=0.5)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xlim(-2000,0)\n",
    "#plt.ylim(0,100)\n",
    "plt.show()\n",
    "# この日しかクラブコインを使えない見たいなルールがあるのか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のペアを選択\n",
    "x = '毎月平均ガチャの取得量'\n",
    "y = '毎月平均ガチャの使用量'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=30, alpha=0.5)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.xlim(-2000,0)\n",
    "#plt.ylim(0,100)\n",
    "plt.show()\n",
    "\n",
    "# 特定の説明変数を選択\n",
    "variable = '毎月平均ガチャの取得量'\n",
    "# 箱ひげ図\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='ラベル', y=variable, data=df_user_merge)\n",
    "plt.title(f'{variable} のクラスタリング結果（箱ひげ図）')\n",
    "plt.show()\n",
    "\n",
    "# ラベルごとのデータ数\n",
    "label_counts = df_user_merge.groupby('ラベル').size()\n",
    "formatted_counts = ', '.join([f\"{label}:{count}\" for label, count in label_counts.items()])\n",
    "print(\"ラベルごとのデータ数:\", formatted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のペアを選択\n",
    "x = '平均rank'\n",
    "y = 'サービス利用開始からの経過日数'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=50, alpha=0.5)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.xlim(0,1000)\n",
    "#plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以下の5グループに分かれる\n",
    "経過日数が浅く、あまりリサイクルしていないグループ<br>\n",
    "経過日数が浅く、ログインしてガチャをたくさん回しているグループ<br>\n",
    "経過日数が長く、あまりリサイクルしていないグループ<br>\n",
    "リサイクルガチ勢<br>\n",
    "ガチャガチ勢<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#性別\n",
    "# 説明変数のペアを選択\n",
    "x = 'gender'\n",
    "y = '毎月平均リサイクル量'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=80, alpha=0.7)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#カード種類\n",
    "# 説明変数のペアを選択\n",
    "x = 'カード種類'\n",
    "y = '毎月平均リサイクル量'\n",
    "# 散布図の作成\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.scatterplot(data=df_user_merge, x=x, y=y, hue='ラベル', palette='bright', s=80, alpha=0.7)\n",
    "plt.title('クラスタリング結果の散布図')\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.legend(title='ラベル', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "店舗との距離←緯度経度をgeocodeで算出<br>\n",
    "\n",
    "レーダーチャート\n",
    "平行座標プロット\n",
    "ツリーマップ（Tree Maps）またはサンキーダイアグラム（Sankey Diagrams）<br>\n",
    "→ツリーマップは主に単一の変数（例えばユーザー数や収益など）の分布を示すために使用されます。各四角形の面積はその変数の大きさを表し、階層的なデータ構造を視覚化するのに適していますが、複数の変数を同時に表現することには限界があるため今回不採用<br>\n",
    "サンキーダイアグラムは時間の経過に伴うクラスタの変化、ユーザーの行動パターンなどを表すときに使う状態変化量を可視化するものなので今回不採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "use_columns = ['毎月平均リサイクル量', '平均rank', 'サービス利用開始からの経過日数','毎月平均ガチャの取得量','age']\n",
    "df_user_merge[use_columns] = scaler.fit_transform(df_user_merge[use_columns])\n",
    "\n",
    "#正規化\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# use_columns = ['毎月平均リサイクル量', '平均rank', 'サービス利用開始からの経過日数', '毎月平均ガチャの取得量','age']\n",
    "# df_user_merge[use_columns] = scaler.fit_transform(df_user_merge[use_columns])\n",
    "\n",
    "\n",
    "# クラスタごとの平均値計算\n",
    "cluster_avgs = df_user_merge[use_columns + ['ラベル']].groupby('ラベル').mean()\n",
    "\n",
    "# レーダーチャートの描画\n",
    "labels=np.array(use_columns)\n",
    "num_vars = len(labels)\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "for idx, row in cluster_avgs.iterrows():\n",
    "    values = row.values.tolist()\n",
    "    display(values)\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, label='Cluster {}'.format(idx))\n",
    "\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# TODO: リサイクル量正規化しておかしくなってないか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行座標プロット\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "parallel_coordinates(df_user_merge[use_columns + ['ラベル']], 'ラベル', color=['#FF5733', '#33FFCE', '#335BFF'], alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: クラスタリング結果はcsv化しよう<br>\n",
    "データ分類の教師あり学習のロジスティック回帰(継続利用するかしないか)、サポートベクターマシンも試したい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_user_merge.groupby('ラベル')['gender'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
