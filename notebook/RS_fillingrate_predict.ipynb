{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "import sys\n",
    "from datetime import datetime, timedelta, time\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import seaborn as sns\n",
    "import random\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# カレントディレクトリを.pyと合わせるために以下を実行\n",
    "from pathlib import Path\n",
    "if Path.cwd().name == \"notebook\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# 親ディレクトリをsys.pathに追加\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Windows MatplotlibのデフォルトフォントをMeiryoに設定\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "\n",
    "\n",
    "# 設定\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.min_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# 自作モジュール\n",
    "from utils.point_history_utils import open_point_history_per_shop, aggregate_date, replace_nan, set_dtype\n",
    "from RS_filliing_rate.RS_fillingrate_test import plot_recycle_period, chi_squared_statistic, exp_func, power_law, KS_statistic, calc_recycle_period\n",
    "\n",
    "\n",
    "# シード値の固定\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac Matplotlibのデフォルトフォントをヒラギノ角ゴシックに設定\n",
    "plt.rcParams['font.family'] = 'Hiragino Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 日付特徴量の追加\n",
    "def add_date_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"month\"] = df[\"年月日\"].dt.month\n",
    "    df[\"day\"] = df[\"年月日\"].dt.day\n",
    "    df[\"year\"] = df[\"年月日\"].dt.year\n",
    "    df['day_of_week'] = df['年月日'].dt.day_name()\n",
    "\n",
    "    df[\"day_sin\"] = np.sin(df[\"day\"] / 31 * 2* np.pi)\n",
    "    df[\"day_cos\"] = np.cos(df[\"day\"] / 31 * 2* np.pi)\n",
    "    df.drop(columns=[\"day\"], inplace=True)\n",
    "    \n",
    "    df[\"month_sin\"] = np.sin(df[\"month\"] / 12 * 2* np.pi)\n",
    "    df[\"month_cos\"] = np.cos(df[\"month\"] / 12 * 2* np.pi)\n",
    "    df.drop(columns=[\"month\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def set_previous_data(df, features, days=28, years=0):\n",
    "    \"\"\"\n",
    "    指定された日数または年数前の特徴量の値を取得する関数。\n",
    "    ※年数と日数のどちらか一方のみ指定可能。\n",
    "    args:\n",
    "        df: データフレーム\n",
    "        features: 特徴量のリスト\n",
    "        days: 日数（デフォルトは28）\n",
    "        years: 年数（デフォルトは0）\n",
    "    return:\n",
    "        df: 更新されたデータフレーム\n",
    "    \"\"\"\n",
    "    # 日付の計算\n",
    "    if years > 0:\n",
    "        df['date_previous'] = df['年月日'].apply(lambda x: x - relativedelta(years=years))\n",
    "        time_label = str(years) + 'years'\n",
    "    else:\n",
    "        df['date_previous'] = df['年月日'] - pd.Timedelta(days=days)\n",
    "        time_label = str(days) + 'days'\n",
    "\n",
    "    for feature in features:\n",
    "        new_feature = feature + '_before_' + time_label\n",
    "        # 一時的なデータフレームを作成\n",
    "        temp_df = df[['年月日', 'super', 'shop_name_1', feature]].copy()\n",
    "        temp_df.rename(columns={'年月日': 'date_previous', feature: new_feature}, inplace=True)\n",
    "\n",
    "        # 元のデータフレームに一時的なデータフレームをマージ\n",
    "        df = df.merge(temp_df, on=['super', 'shop_name_1', 'date_previous'], how='left')\n",
    "\n",
    "    # 不要な列を削除\n",
    "    df.drop('date_previous', axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/input/point_history_per_shop_date.csv', encoding='utf-8')\n",
    "\n",
    "df = set_dtype(df)\n",
    "df = replace_nan(df)\n",
    "df = add_date_features(df)\n",
    "df.loc[df[\"filling_rate\"] > 1, \"filling_rate\"] = 1\n",
    "df = set_previous_data(df, ['amount_kg', 'filling_rate'], days=28)\n",
    "df = set_previous_data(df, ['amount_kg', 'filling_rate'], years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['shop_id', 'shop_name', 'shop_id_1', 'リサイクル分類ID', '支店ID', 'store_opening_time',\\\n",
    "                    'store_closing_time', 'rps_opening_time', 'rps_closing_time','年月日', 'interval_compared_to_next', \\\n",
    "                        'amount','amount_kg','point','total_point','total_amount','coin', 'interval_compared_to_previous', 'total_amount_kg_per_day',\\\n",
    "                             '合計全天日射量(MJ/㎡)', '降雪量合計(cm)', '降水量の合計(mm)', '日照時間(時間)']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Handle categorical variables with one-hot encoding\n",
    "categorical_features = ['prefectures', 'municipality','shop_name_1','super', '天気', 'day_of_week']\n",
    "df = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('filling_rate', axis=1)\n",
    "y = df['filling_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions\n",
    "# Calculate and print evaluation metrics\n",
    "def evaluate_the_predictions(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "    print(f'R-squared (R2): {r2}')\n",
    "    \n",
    "    print(\"actual\")\n",
    "    print(y_test[:10].values)\n",
    "    print(\"pred\")\n",
    "    print(y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LightGBM model\n",
    "\n",
    "# SimpleImputerを中央値で初期化します\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# # DataFrameのNaN値を中央値で埋めます\n",
    "# X_train['平均雲量(10分比)'] = pd.DataFrame(imputer.fit_transform(X_train['平均雲量(10分比)'].values.reshape(-1, 1)), columns=['平均雲量(10分比)'])\n",
    "# X_test['平均雲量(10分比)'] = pd.DataFrame(imputer.fit_transform(X_test['平均雲量(10分比)'].values.reshape(-1, 1)), columns=['平均雲量(10分比)'])\n",
    "\n",
    "# # NaN値を0で埋めます\n",
    "# X_train['平均雲量(10分比)'].fillna(0, inplace=True)\n",
    "# X_test['平均雲量(10分比)'].fillna(0, inplace=True)\n",
    "\n",
    "# 正規化\n",
    "# StandardScalerを初期化します\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# normalized_columns = ['平均気温(℃)','最高気温(℃)','最低気温(℃)','平均風速(m/s)','平均湿度(％)','平均現地気圧(hPa)','平均雲量(10分比)']\n",
    "# # DataFrameを正規化します\n",
    "# X[normalized_columns] = pd.DataFrame(scaler.fit_transform(X[normalized_columns]), columns=normalized_columns)\n",
    "\n",
    "\n",
    "# -------------------- 上記は精度が下がったのでコメントアウト -------------------------\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'goss',\n",
    "    'seed': 0,\n",
    "    'early_stopping_rounds' : 1000,\n",
    "     'num_iterations' : 10000,\n",
    "     'learning_rate' : 0.02,\n",
    "     'max_depth': 8,\n",
    "    # 'bagging_freq': 10,  # バギングを行う頻度\n",
    "    # 'bagging_fraction': 0.6,  # バギングの割合\n",
    "    # 'feature_fraction': 0.6,  # 特徴量サブサンプルの割合\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "model = lgb.train(lgb_params, train_data, valid_sets=test_data)\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "#モデル評価\n",
    "evaluate_the_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレストの場合\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# パイプラインの作成\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # 欠損値の代入\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=100, # 決定木の数 200にしてもさほど変化なし\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt', # デフォルト:None\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# # クロスバリデーションの設定 時間かかるのでコメントアウト推奨\n",
    "# cv = 5\n",
    "# mse_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "# mae_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "# r2_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "# # クロスバリデーションの結果を出力\n",
    "# print(f'Cross-Validated Mean Squared Error (MSE): {-np.mean(mse_scores)}')\n",
    "# print(f'Cross-Validated Mean Absolute Error (MAE): {-np.mean(mae_scores)}')\n",
    "# print(f'Cross-Validated R-squared (R2): {np.mean(r2_scores)}')\n",
    "\n",
    "\n",
    "# 訓練データとテストデータを使用したモデルの訓練と評価\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# モデルの評価\n",
    "evaluate_the_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.title('決定係数: {}'.format(round(r2, 2)))\n",
    "plt.xlabel('充填率（正解値）')\n",
    "plt.ylabel('充填率（予測値）')\n",
    "\n",
    "# Plot a line representing perfect predictions\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特徴量の重要性を取得\n",
    "feature_importances = model.feature_importance(importance_type='split')\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 2. 特徴量の名前とその重要性を組み合わせてDataFrameを作成\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# 3. DataFrameを重要性でソート\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. 特徴量の重要性を棒グラフで表示\n",
    "plt.figure(figsize=(5, 100))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('予測における重要度')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムフォレスト※欠損値補正必要\n",
    "HistGradientBoostingRegressor※ワンホットベクター不要、欠損値補正不要\n",
    "XGBoost\n",
    "サポートベクターマシン\n",
    "ニューラルネットワーク\n",
    "リッジ回帰 (Ridge Regression) とラッソ回帰 (Lasso Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amount_kg予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['shop_id', 'shop_name', 'shop_id_1', 'リサイクル分類ID', '支店ID', 'store_opening_time',\\\n",
    "                    'store_closing_time', 'rps_opening_time', 'rps_closing_time','年月日', 'interval_compared_to_next', \\\n",
    "                        'amount','point','total_point','total_amount','coin', 'interval_compared_to_previous', 'total_amount_kg_per_day',\\\n",
    "                            'store_latitude', 'store_longitude', '合計全天日射量(MJ/㎡)', '降雪量合計(cm)', '降水量の合計(mm)', '日照時間(時間)', 'filling_rate']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical variables with one-hot encoding\n",
    "categorical_features = ['prefectures', 'municipality','shop_name_1','super', '天気', 'day_of_week']\n",
    "df = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('amount_kg', axis=1)\n",
    "y = df['amount_kg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'seed': 0,\n",
    "    'early_stopping_rounds' : 1000,\n",
    "     'num_iterations' : 10000,\n",
    "     'learning_rate' : 0.02,\n",
    "     'max_depth': 8,\n",
    "}\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_train, label=y_train)\n",
    "model = lgb.train(lgb_params, train_data, valid_sets=test_data)\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Evaluate the predictions\n",
    "# Calculate and print evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R-squared (R2): {r2}')\n",
    "\n",
    "print(\"actual\")\n",
    "print(y_test[:10].values)\n",
    "print(\"pred\")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.title('決定係数: {}'.format(round(r2, 2)))\n",
    "plt.xlabel('充填率（正解値）')\n",
    "plt.ylabel('充填率（予測値）')\n",
    "\n",
    "# Plot a line representing perfect predictions\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特徴量の重要性を取得\n",
    "feature_importances = model.feature_importance(importance_type='split')\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 2. 特徴量の名前とその重要性を組み合わせてDataFrameを作成\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# 3. DataFrameを重要性でソート\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. 特徴量の重要性を棒グラフで表示\n",
    "plt.figure(figsize=(5, 100))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('予測における重要度')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/input/point_history_per_shop_date.csv', encoding='utf-8')\n",
    "\n",
    "df = set_dtype(df)\n",
    "df = replace_nan(df)\n",
    "df = add_date_features(df)\n",
    "df.loc[df[\"filling_rate\"] > 1, \"filling_rate\"] = 1\n",
    "df = set_previous_data(df, ['amount_kg', 'filling_rate'], days=28)\n",
    "df = set_previous_data(df, ['amount_kg', 'filling_rate'], years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['amount_kg'] > 3000, '年月日'].dt.strftime('%m-%d').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
